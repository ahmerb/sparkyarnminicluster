/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package sparkyarnminicluster;

import com.holdenkarau.spark.testing.Utils;
import com.holdenkarau.spark.testing.YARNCluster;
import java.io.File;
import java.util.Arrays;
import java.util.Collections;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

public class HelloSpark {
    public static YARNCluster yarnCluster = null;
    public static JavaSparkContext jsc = null;

    public static void beforeClass() {
      yarnCluster = new YARNCluster();
      yarnCluster.startYARN();

      SparkConf conf = new SparkConf().setMaster("yarn-client").setAppName("Test with YARN MiniCluster");
      jsc = new JavaSparkContext(conf);
    }

    public static void testRunningSimpleCount() {
      // create a simple rdd
      JavaRDD<Integer> rdd = jsc.parallelize(Arrays.asList(1, 2, 3, 4));
      // log its count
      System.out.println("Count: " + rdd.count());
    }

    public static void main(String[] args) {
      System.out.println("***** Started :D");
      beforeClass();
      testRunningSimpleCount();
      afterClass();
      System.out.println("***** Done :D");
    }

  //  public void testSaveAndLoadRDD() {
  //    // create a simple rdd with this string
  //    String originalString = "Hello, Hi, Hay, How are you ?";
  //    JavaRDD<String> rdd = jsc.parallelize(Collections.singletonList(originalString));
  //    // save this rdd to a directory
  //    File dir = Utils.createTempDir(System.getProperty("java.io.tmpdir"));
  //    rdd.saveAsTextFile(dir.getAbsolutePath());
  //    // read this rdd and assert the string is correct
  //    String readString = jsc.textFile(dir.getAbsolutePath()).collect().get(0);
  //    assertEquals(originalString, readString);
  //  }

    public static void afterClass() {
      if (jsc != null) {
        jsc.stop();
      }
      if (yarnCluster != null) {
        yarnCluster.shutdownYARN();
      }
    }
}
